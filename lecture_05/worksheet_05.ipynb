{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Haoxiang Huo\n",
    "UID: U13668934\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration 1:\n",
    "Assignments: {0, 0.5} and {1.5, 2, 6, 6.5, 7};\n",
    "Updated centroids: [0.25, 4.4];\n",
    "\n",
    "Iteration 2:\n",
    "Assignments: {0, 0.5, 1.5, 2} and {6, 6.5, 7};\n",
    "Updated centroids: [1, 6.5];\n",
    "\n",
    "Iteration 3:\n",
    "Assignments don't change from Iteration 2 and centroids remain [1, 6.5]. Algorithm converges.\n",
    "\n",
    "Final Clusters:\n",
    "Cluster 1: [0, .5, 1.5, 2];\n",
    "Cluster 2: [6, 6.5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function for k-means measures how far data points are from the center of their assigned clusters. It's a way to gauge how well the points fit within their clusters. The goal of the k-means algorithm is to minimize this cost function, meaning we want to make sure that data points are as close as possible to the center of their respective clusters. If all the data points are right at the center of their clusters, the cost would be zero, which would be an ideal scenario. But in most cases, points are spread out, and the cost function helps us understand how spread out they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order in which data points are processed might affect the clustering outcome, especially in online or mini-batch versions of k-means. On the other hand, if the data isn't well-separated or if there are no clear cluster boundaries, k-means can produce different clustering results. This is especially true if the number of specified clusters (K) doesn't align well with the actual structure in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, always converge. The objective of Lloyd's algorithm (or k-means) is to minimize the sum of squared distances from each point to its assigned centroid. In each step of the algorithm, either:\n",
    "\n",
    "a) A point's assignment to a centroid changes, which means that the distance to its new centroid is shorter than the distance to its old centroid. This ensures a decrease in the overall cost.\n",
    "\n",
    "Or, \n",
    "b) the centroids are recalculated, which by definition will be at the mean of its assigned points, minimizing the sum of squared distances for that cluster.\n",
    "\n",
    "Given that there's a finite number of possible ways to assign data points to centroids, and in each step the overall cost either decreases or remains the same, the algorithm will eventually reach a point where no further improvement is possible, ensuring convergence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def distance(self, x, y):\n",
    "        return np.linalog.norm(x - y)\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "    def initialize(self):\n",
    "        return self.data[np.random.choice(range(len(self.data)), self.k, replace=False)]\n",
    "    \n",
    "    def assign(self, centers):\n",
    "        for i in range(len(self.data)):\n",
    "            min = self.distance(centers[0], self.data[i])\n",
    "            self.assignment[i] = 0\n",
    "            for j in range(1, len(centers)):\n",
    "                dist = self.distance(centers[j], self.data[i])\n",
    "                if dist < min:\n",
    "                    min = dist\n",
    "                    self.assignment[i] = j\n",
    "        return \n",
    "    \n",
    "    def is_diff_clusters(self,centers, new_centers):\n",
    "        for i in range(len(centers)):\n",
    "            if self.distance(centers[i], new_centers[i]) != 0:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def get_centers(self):\n",
    "        centers = []\n",
    "        for i in set(self.assignment):\n",
    "            clusters = [self.data[j] for j in range(len(self.data)) if self.assignment[j] == i]\n",
    "            centers.append(np.mean(clusters, axis=0))\n",
    "        return np.array(centers)\n",
    "    \n",
    "    \n",
    "    def lloyds(self):\n",
    "        centers = self.initialize()\n",
    "        self.assign(centers)\n",
    "        self.snap(centers)\n",
    "        new_centers = self.get_centers()\n",
    "        while self.is_diff_clusters(centers, new_centers):\n",
    "            self.assign(new_centers)\n",
    "            self.snap(new_centers)\n",
    "            centers = new_centers.copy()\n",
    "            new_centers = self.get_centers()\n",
    "        return\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
