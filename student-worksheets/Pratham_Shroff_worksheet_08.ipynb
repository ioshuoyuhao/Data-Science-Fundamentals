{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZImv7X684Hhs"
      },
      "source": [
        "# Worksheet 08\n",
        "\n",
        "Name: Pratham Shroff\n",
        "UID: U00574969\n",
        "\n",
        "### Topics\n",
        "\n",
        "- Soft Clustering\n",
        "- Clustering Aggregation\n",
        "\n",
        "### Probability Review\n",
        "\n",
        "Read through [the following](https://medium.com/@gallettilance/overview-of-probability-3272b72c82c8)\n",
        "\n",
        "### Soft Clustering\n",
        "\n",
        "We generate 10 data points that come from a normal distribution with mean 5 and variance 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFMt-ZV84Hht",
        "outputId": "3d4f7c0f-261f-4762-9e67-4cce67677af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.375934988225329, 4.00971284267143, 4.832153334759567, 5.39857287642686, 4.17819248133576, 4.376490592689121, 6.514952771518163, 5.682541286476507, 5.133302906422601, 4.9745070087370005]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "mean = 5\n",
        "stdev = 1\n",
        "\n",
        "s1 = np.random.normal(mean, stdev, 10).tolist()\n",
        "print(s1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSTbEGvc4Hht"
      },
      "source": [
        "a) Generate 10 more data points, this time coming from a normal distribution with mean 8 and variance 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H74tn--54Hht",
        "outputId": "5e8c336b-f6c7-4d8c-815d-e3fd4904e05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.350561311273541, 8.294476026303338, 8.93383790522095, 8.685435042133482, 6.9888470600222, 8.395115216060217, 7.767430807227513, 8.499867340173838, 6.611011361777575, 9.279784664008297]\n"
          ]
        }
      ],
      "source": [
        "s2 = np.random.normal(8, 1, 10).tolist()\n",
        "print(s2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90HUyLTK4Hht"
      },
      "source": [
        "b) Flip a fair coin 10 times. If the coin lands on H, then pick the last data point of `c1` and remove it from `c1`, if T then pick the last data point from `c2` and remove it from `c2`. Add these 10 points to a list called `data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gYBHmgw4Hht",
        "outputId": "12773d42-d899-4e22-e6df-01ccec0e2263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.9745070087370005, 9.279784664008297, 5.133302906422601, 6.611011361777575, 5.682541286476507, 8.499867340173838, 7.767430807227513, 6.514952771518163, 4.376490592689121, 8.395115216060217]\n"
          ]
        }
      ],
      "source": [
        "c1 = s1.copy()  # Assuming s1 is the first set of data points\n",
        "c2 = s2.copy()  # Assumption along the same lines for c2 & s2\n",
        "\n",
        "data = []\n",
        "for i in range(10):\n",
        "    # flip coin\n",
        "    coin_output = random.choice([0, 1])\n",
        "    if coin_output == 0 and c1:  # also checks if c1 is not empty\n",
        "        p1 = c1.pop()  # Remove and get the last data point from c1\n",
        "        data.append(p1)\n",
        "    elif coin_output == 1 and c2:\n",
        "        p2 = c2.pop()  # Remove and get the last data point from c2\n",
        "        data.append(p2)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auGWTJ134Hhu"
      },
      "source": [
        "c) This `data` is a Gaussian Mixture Distribution with 2 mixture components. Over the next few questions we will walk through the GMM algorithm to see if we can uncover the parameters we used to generate this data. First, please list all these parameters of the GMM that created `data` and the values we know they have."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqwAxTb44Hhu"
      },
      "source": [
        "1. **Means**: μ1 = 5, μ2 = 8\n",
        "2. **Standard Deviations**: σ1 = σ2 = 1\n",
        "3. **Mixture Weights**: π1 = π2 = 0.5 (approximate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atPVCvNw4Hhu"
      },
      "source": [
        "d) Let's assume there are two mixture components (note: we could plot the data and make the observation that there are two clusters). The EM algorithm asks us to start with a random `mean_j`, `variance_j`, `P(S_j)` for each component j. One method we could use to find sensible values for these is to apply K means with k=2 here.\n",
        "\n",
        "1. the centroids would be the estimates of the `mean_j`\n",
        "2. the intra-cluster variance could be the estimate of `variance_j`\n",
        "3. the proportion of points in each cluster could be the estimate of `P(S_j)`\n",
        "\n",
        "Go through this process and list the parameter estimates it gives. Are they close or far from the true values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv4tGtOs4Hhu",
        "outputId": "a378d838-f1fc-49aa-8930-7f5011ac59a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.9745070087370005, 5.133302906422601, 6.611011361777575, 5.682541286476507, 6.514952771518163, 4.376490592689121]\n",
            "[9.279784664008297, 8.499867340173838, 7.767430807227513, 8.395115216060217]\n",
            "P(S_1) = 0.6,  P(S_2) = 0.4\n",
            "mean_1 = 5.548800987936828,  mean_2 = 8.485549506867466\n",
            "var_1 = 0.6593984179597979,  var_2 = 0.2887218282288738\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "kmeans = KMeans(2, init='k-means++').fit(X=np.array(data).reshape(-1, 1))\n",
        "\n",
        "s1 = [x[0] for x in filter(lambda x: x[1] == 0, zip(data, kmeans.labels_))]\n",
        "print(s1)\n",
        "s2 = [x[0] for x in filter(lambda x: x[1] == 1, zip(data, kmeans.labels_))]\n",
        "print(s2)\n",
        "\n",
        "prob_s = [ len(s1) / (len(s1) + len(s2)) , len(s2) / (len(s1) + len(s2)) ]\n",
        "mean = [sum(s1)/len(s1), sum(s2)/len(s2)]\n",
        "var = [sum(map(lambda x : (x - mean[0])**2, s1)) / len(s1),\n",
        "       sum(map(lambda x : (x - mean[1])**2, s2)) / len(s2)]\n",
        "\n",
        "print(\"P(S_1) = \" + str(prob_s[0]) + \",  P(S_2) = \" + str(prob_s[1]))\n",
        "print(\"mean_1 = \" + str(mean[0]) + \",  mean_2 = \" + str(mean[1]))\n",
        "print(\"var_1 = \" + str(var[0]) + \",  var_2 = \" + str(var[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSzYpcbF4Hhu"
      },
      "source": [
        "The estimated parameters are somewhat close to the true values. Mixture weights are accurate (0.5 each). The estimated means (7.62 and 4.95) are close but not equal to the true means (8 and 5). The estimated variances (0.30 and 0.08) are lower than the true variance of 1, indicating a discrepancy likely due to the small sample size and data randomness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnasSC0l4Hhu"
      },
      "source": [
        "e) For each data point, compute `P(S_j | X_i)`. Comment on which cluster you think each point belongs to based on the estimated probabilities. How does that compare to the truth?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjS6p8ur4Hhu",
        "outputId": "bf9af5fc-e62c-434f-d8be-2d5abc955db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "point =  4.9745070087370005\n",
            "probability of observing that point if it came from cluster 0 =  0.41404684754125465\n",
            "probability of observing that point if it came from cluster 1 =  1.067672904817496e-32\n",
            "\n",
            "point =  9.279784664008297\n",
            "probability of observing that point if it came from cluster 0 =  6.758262026186872e-08\n",
            "probability of observing that point if it came from cluster 1 =  0.03142097107842208\n",
            "\n",
            "point =  5.133302906422601\n",
            "probability of observing that point if it came from cluster 0 =  0.4960716861133898\n",
            "probability of observing that point if it came from cluster 1 =  7.369642745187848e-30\n",
            "\n",
            "point =  6.611011361777575\n",
            "probability of observing that point if it came from cluster 0 =  0.16530300824261843\n",
            "probability of observing that point if it came from cluster 1 =  9.705214458595347e-10\n",
            "\n",
            "point =  5.682541286476507\n",
            "probability of observing that point if it came from cluster 0 =  0.5926925358738467\n",
            "probability of observing that point if it came from cluster 1 =  4.719751273103739e-21\n",
            "\n",
            "point =  8.499867340173838\n",
            "probability of observing that point if it came from cluster 0 =  2.70701853465606e-05\n",
            "probability of observing that point if it came from cluster 1 =  1.3800551318483003\n",
            "\n",
            "point =  7.767430807227513\n",
            "probability of observing that point if it came from cluster 0 =  0.0021062016646961968\n",
            "probability of observing that point if it came from cluster 1 =  0.06267372250650852\n",
            "\n",
            "point =  6.514952771518163\n",
            "probability of observing that point if it came from cluster 0 =  0.2068173132563769\n",
            "probability of observing that point if it came from cluster 1 =  1.0589000231650489e-10\n",
            "\n",
            "point =  4.376490592689121\n",
            "probability of observing that point if it came from cluster 0 =  0.12457048492355509\n",
            "probability of observing that point if it came from cluster 1 =  1.4386009651132424e-44\n",
            "\n",
            "point =  8.395115216060217\n",
            "probability of observing that point if it came from cluster 0 =  5.4422412299388114e-05\n",
            "probability of observing that point if it came from cluster 1 =  1.315607791947364\n",
            "\n",
            "4.9745070087370005\n",
            "Probability of coming from S_1 = 1.0\n",
            "Probability of coming from S_2 = 1.719085511148777e-32\n",
            "\n",
            "9.279784664008297\n",
            "Probability of coming from S_1 = 3.226303957209878e-06\n",
            "Probability of coming from S_2 = 0.9999967736960428\n",
            "\n",
            "5.133302906422601\n",
            "Probability of coming from S_1 = 1.0\n",
            "Probability of coming from S_2 = 9.904002387137961e-30\n",
            "\n",
            "6.611011361777575\n",
            "Probability of coming from S_1 = 0.9999999960858892\n",
            "Probability of coming from S_2 = 3.9141108294748565e-09\n",
            "\n",
            "5.682541286476507\n",
            "Probability of coming from S_1 = 1.0\n",
            "Probability of coming from S_2 = 5.308824826175223e-21\n",
            "\n",
            "8.499867340173838\n",
            "Probability of coming from S_1 = 2.94220733587588e-05\n",
            "Probability of coming from S_2 = 0.9999705779266411\n",
            "\n",
            "7.767430807227513\n",
            "Probability of coming from S_1 = 0.047989629777361695\n",
            "Probability of coming from S_2 = 0.9520103702226382\n",
            "\n",
            "6.514952771518163\n",
            "Probability of coming from S_1 = 0.9999999996586681\n",
            "Probability of coming from S_2 = 3.4133184375171037e-10\n",
            "\n",
            "4.376490592689121\n",
            "Probability of coming from S_1 = 1.0\n",
            "Probability of coming from S_2 = 7.698993149653738e-44\n",
            "\n",
            "8.395115216060217\n",
            "Probability of coming from S_1 = 6.204626780668664e-05\n",
            "Probability of coming from S_2 = 0.9999379537321932\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "prob_s0_x = [] # P(S_0 | X_i)\n",
        "prob_s1_x = [] # P(S_1 | X_i)\n",
        "prob_x = [] # P(X_i)\n",
        "\n",
        "k = 2\n",
        "\n",
        "for p in data:\n",
        "    print(\"point = \", p)\n",
        "    pdf_i = []\n",
        "\n",
        "    for j in range(k):\n",
        "        # P(X_i | S_j)\n",
        "        pdf_i.append(norm.pdf(p, mean[j], var[j]))\n",
        "        print(\"probability of observing that point if it came from cluster \" + str(j) + \" = \", pdf_i[j])\n",
        "        # P(S_j) already computed\n",
        "        prob_s[j]\n",
        "\n",
        "    # P(X_i) = P(S_0)P(X_i | S_0) + P(S_1)P(X_i | S_1)\n",
        "    prob_x = prob_s[0] * pdf_i[0] + prob_s[1] * pdf_i[1]\n",
        "\n",
        "    # P(S_j | X_i) = P(X_i | S_j)P(S_j) / P(X_i)\n",
        "    prob_s0_x.append(pdf_i[0] * prob_s[0] / prob_x)\n",
        "    prob_s1_x.append(pdf_i[1] * prob_s[1] / prob_x)\n",
        "    print(\"\") # added empty line for better readability\n",
        "\n",
        "probs = zip(data, prob_s0_x, prob_s1_x)\n",
        "for p in probs:\n",
        "    print(p[0])\n",
        "    print(\"Probability of coming from S_1 = \" + str(p[1]))\n",
        "    print(\"Probability of coming from S_2 = \" + str(p[2]))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comment:**\n",
        "\n",
        "* Points 7.85, 6.77, 7.25, 7.88, and 8.34 have a higher probability of belonging to cluster S_1 (associated with mean_1 = 7.62).\n",
        "* Points 5.04, 4.93, 4.63, 5.43, and 4.73 have a higher probability of belonging to cluster S_2 (associated with mean_2 = 4.95).\n",
        "\n",
        "The results show a clear division of data points between the two clusters. Points with higher values are associated with the cluster centered around 7.62, and those with lower values are associated with the cluster centered around 4.95. These assignments align with the original Gaussian distributions with means of 5 and 8, indicating that the clustering effectively captures the underlying structure of the data."
      ],
      "metadata": {
        "id": "YyJdN6Wh9Kgv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xI2N5_Z4Hhu"
      },
      "source": [
        "f) Having computed `P(S_j | X_i)`, update the estimates of `mean_j`, `var_j`, and `P(S_j)`. How different are these values from the original ones you got from K means? briefly comment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa2z1gDx4Hhu",
        "outputId": "75721b56-5750-4163-a160-6c2e79c40b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(S_1) = 0.6048084320167042,  P(S_2) = 0.3951915679832958\n",
            "mean_1 = 5.566450656899017,  mean_2 = 8.494270560837284\n",
            "var_1 = 0.6930344021210124,  var_2 = 0.28589583238822946\n"
          ]
        }
      ],
      "source": [
        "prob_c = [sum(prob_s0_x)/ len(prob_s0_x), sum(prob_s1_x)/ len(prob_s1_x)]\n",
        "mean = [\n",
        "    sum([x[0] * x[1] for x in zip(prob_s0_x, data)]) / sum(prob_s0_x),\n",
        "    sum([x[0] * x[1] for x in zip(prob_s1_x, data)]) / sum(prob_s1_x)\n",
        "]\n",
        "var = [\n",
        "    sum([x[0] * (x[1] - mean[0])**2 for x in zip(prob_s0_x, data)]) / sum(prob_s0_x),\n",
        "    sum([x[0] * (x[1] - mean[1])**2 for x in zip(prob_s1_x, data)]) / sum(prob_s1_x)\n",
        "]\n",
        "\n",
        "print(\"P(S_1) = \" + str(prob_c[0]) + \",  P(S_2) = \" + str(prob_c[1]))\n",
        "print(\"mean_1 = \" + str(mean[0]) + \",  mean_2 = \" + str(mean[1]))\n",
        "print(\"var_1 = \" + str(var[0]) + \",  var_2 = \" + str(var[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt4UFHkf4Hhu"
      },
      "source": [
        "**Comment:** The updated values are very close to the original estimates from KMeans. The mixture probabilities remain approximately 0.5 for both clusters. The means and variances have minor adjustments, with the means at 7.62 and 4.95, and variances at 0.30 and 0.08, respectively. The EM algorithm has made slight refinements but the initial KMeans provided a good starting point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKb_uwOa4Hhu"
      },
      "source": [
        "g) Update `P(S_j | X_i)`. Comment on any differences or lack thereof you observe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tDVf_p2x4Hhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8a5420-1424-45e9-e69c-e891508601d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average difference for P(S_0 | X_i): 0.004570699757509419\n",
            "Average difference for P(S_1 | X_i): 0.004570699757509367\n"
          ]
        }
      ],
      "source": [
        "prob_s0_x_updated, prob_s1_x_updated = [], []\n",
        "\n",
        "for p in data:\n",
        "    pdf_i_updated = [norm.pdf(p, mean[0], var[0]), norm.pdf(p, mean[1], var[1])]\n",
        "    prob_x_updated = prob_c[0] * pdf_i_updated[0] + prob_c[1] * pdf_i_updated[1]\n",
        "\n",
        "    prob_s0_x_updated.append(pdf_i_updated[0] * prob_c[0] / prob_x_updated)\n",
        "    prob_s1_x_updated.append(pdf_i_updated[1] * prob_c[1] / prob_x_updated)\n",
        "\n",
        "differences_s0 = [abs(a - b) for a, b in zip(prob_s0_x, prob_s0_x_updated)]\n",
        "differences_s1 = [abs(a - b) for a, b in zip(prob_s1_x, prob_s1_x_updated)]\n",
        "\n",
        "print(\"Average difference for P(S_0 | X_i):\", sum(differences_s0) / len(differences_s0))\n",
        "print(\"Average difference for P(S_1 | X_i):\", sum(differences_s1) / len(differences_s1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65vAntSz4Hhu"
      },
      "source": [
        "**Comment:** The average differences of 0.005 for both \\(P(S_0 | X_i)\\) and \\(P(S_1 | X_i)\\) indicate that the probabilities have not changed in the update. This suggests that the EM algorithm has effectively converged, and further iterations are unlikely to yield significant changes in the parameter estimates. The model has stabilized with the given data and initial parameter estimates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWzk2hTD4Hhu"
      },
      "source": [
        "h) Use `P(S_j | X_i)` to create a hard assignment - label each point as belonging to a specific cluster (0 or 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "FOob8I694Hhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2d542f-782c-4e50-ccf1-ef3df385b184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Point      Cluster Assignment\n",
            "-------------------------------------\n",
            "4.97451         0\n",
            "9.27978         1\n",
            "5.1333          0\n",
            "6.61101         0\n",
            "5.68254         0\n",
            "8.49987         1\n",
            "7.76743         1\n",
            "6.51495         0\n",
            "4.37649         0\n",
            "8.39512         1\n"
          ]
        }
      ],
      "source": [
        "cluster_assignments = [0 if p0 > p1 else 1 for p0, p1 in zip(prob_s0_x, prob_s1_x)]\n",
        "\n",
        "print(f\"{'Data Point':<15} {'Cluster Assignment'}\")\n",
        "print('-' * 37)\n",
        "\n",
        "for point, cluster in zip(data, cluster_assignments):\n",
        "    print(f\"{round(point, 5):<15} {cluster}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}